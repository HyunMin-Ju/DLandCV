{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms,models,datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import cv2, glob, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q kaggle\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!ls ~/.kaggle\n",
    "!kaggle datasets download -d chiragsoni/ferdata\n",
    "!unzip ferdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = 'train/'\n",
    "valid_data_dir = 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FacialEmotionDataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        angry = glob(folder + 'angry/*.jpg') \n",
    "        disgust = glob(folder + 'disgust/*.jpg') \n",
    "        fear = glob(folder + 'fear/*.jpg')\n",
    "        happy = glob(folder + 'happy/*.jpg')\n",
    "        neutral = glob(folder + 'neutral/*.jpg')\n",
    "        sad = glob(folder + 'sad/*.jpg')\n",
    "        surprise = glob(folder + 'surprise/*.jpg')\n",
    "        self.fpaths = angry + disgust + fear + happy + neutral + sad + surprise\n",
    "\n",
    "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "        from random import shuffle, seed; seed(10); shuffle(self.fpaths)\n",
    "        self.idx2emotion = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "        self.emotion2idx = {emotion:ix for ix, emotion in enumerate(self.idx2emotion)}\n",
    "        self.targets = [self.emotion2idx[path_name.split('/')[-2]] for path_name in self.fpaths]\n",
    "    def __len__(self): return len(self.fpaths)\n",
    "    def __getitem__(self, ix):\n",
    "        f = self.fpaths[ix]\n",
    "        target = self.targets[ix]\n",
    "        im = (cv2.imread(f)[:,:,::-1])\n",
    "        im = cv2.resize(im, (48,48))\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        im = torch.tensor(im/255)\n",
    "        im = im.permute(2,0,1)\n",
    "        im = self.normalize(im) \n",
    "        return im.float().to(device), torch.tensor(target).to(device)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = FacialEmotionDataset(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, 100)\n",
    "im, label = data[idx]\n",
    "plt.imshow(im.permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in model.layer4.parameters():\n",
    "        param.requires_grad = True\n",
    "    model.fc = nn.Sequential(\n",
    "        nn.Linear(512, 7),\n",
    "    )\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr= 1e-3)\n",
    "    return model.to(device), loss_fn, optimizer\n",
    "model, loss_fn, optimizer = get_model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch_summary\n",
    "from torchsummary import summary\n",
    "model, criterion, optimizer = get_model()\n",
    "summary(model, torch.zeros(1,3,48,48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    max_values, argmaxes = prediction.max(-1)\n",
    "    is_correct = argmaxes == y\n",
    "    return is_correct.cpu().numpy().tolist()\n",
    "\n",
    "@torch.no_grad()\n",
    "def val_loss(x, y, model, loss_fn):\n",
    "    model.eval()\n",
    "    prediction = model(x)\n",
    "    val_loss = loss_fn(prediction, y)\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = FacialEmotionDataset(train_data_dir)\n",
    "    trn_dl = DataLoader(train, batch_size=32, shuffle=True, drop_last = True)\n",
    "    val = FacialEmotionDataset(valid_data_dir)\n",
    "    val_dl = DataLoader(val, batch_size=32, shuffle=True, drop_last = True)\n",
    "    return trn_dl, val_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl, val_dl = get_data()\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "train_losses, train_accuracies = [], []\n",
    "for epoch in range(num_epochs):\n",
    "  train_epoch_losses, train_epoch_accuracies = [], []\n",
    "  for ix, batch in enumerate(iter(trn_dl)):\n",
    "    x, y = batch\n",
    "    batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "    train_epoch_losses.append(batch_loss)        \n",
    "  train_epoch_loss = np.array(train_epoch_losses).mean()\n",
    "\n",
    "  for ix, batch in enumerate(iter(trn_dl)):\n",
    "    x, y = batch\n",
    "    is_correct = accuracy(x, y, model)\n",
    "    train_epoch_accuracies.extend(is_correct)\n",
    "  train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
    "\n",
    "  # validation loss\n",
    "  # model.eval()\n",
    "  val_epoch_losses, val_epoch_accuracies = [], []\n",
    "  for ix, batch in enumerate(iter(val_dl)):\n",
    "    x, y = batch\n",
    "    val_batch_loss = val_loss(x, y, model, loss_fn)\n",
    "    val_is_correct = accuracy(x, y, model)\n",
    "\n",
    "    val_epoch_losses.append(val_batch_loss)\n",
    "    val_epoch_accuracies.extend(val_is_correct)\n",
    "  val_epoch_loss = np.mean(val_epoch_losses)\n",
    "  val_epoch_accuracy = np.mean(val_epoch_accuracies)\n",
    "  # scheduler.step(val_epoch_loss)\n",
    "\n",
    "  # append to losses and accuracies\n",
    "  train_losses.append(train_epoch_loss)\n",
    "  train_accuracies.append(train_epoch_accuracy)\n",
    "  val_losses.append(val_epoch_loss)\n",
    "  val_accuracies.append(val_epoch_accuracy)\n",
    "  print(f\"epoch {epoch + 1}/{num_epochs}, train_epoch_loss:{train_epoch_loss}, train_epoch_accuracy: {train_epoch_accuracy}, val_epoch_accuracy: {val_epoch_accuracy}\")\n",
    "\n",
    "print(f'Min training loss: {min(train_losses):.4f}')\n",
    "print(f'Max training accuracy: {max(train_accuracies):.4f}')\n",
    "print(f'Min validation loss: {min(val_losses):.4f}')\n",
    "print(f'Max validation accuracy: {max(val_accuracies):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracies\n",
    "plt.plot(train_accuracies, label='Training accuracy', color='blue', linestyle='--')\n",
    "plt.plot(val_accuracies, label='Validation accuracy', color='red')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy value over increasing epochs')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_accuracies)\n",
    "print(val_accuracies)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
